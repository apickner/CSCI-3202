{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI 3202, Spring 2020\n",
    "\n",
    "# Wednesday January 22, 2020\n",
    "\n",
    "# In-class notebook:  Agents\n",
    "\n",
    "<a id='top'></a>\n",
    "\n",
    "<br>\n",
    "\n",
    "### Your name(s):\n",
    "\n",
    "<br>\n",
    "\n",
    "* When you submit this to Moodle, be sure to include all of your group members' names.\n",
    "* You may work in groups of up to 5 people,\n",
    "* but **all people** in the group must submit the assignment on their own Moodle account.\n",
    "\n",
    "---\n",
    "\n",
    "Shortcuts:  [Top](#top) || [0](#p0) || [1](#p1) | [1a](#p1a) | [1b](#p1b) | [1c](#p1c) | [1d](#p1d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you begin, load the packages below (you might find they are handy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Problem 0\n",
    "\n",
    "<a/ id='p0'></a>\n",
    "\n",
    "#### Set up and representing the task environment\n",
    "\n",
    "Let's design some worlds! Specifically, we want to represent things like a brave knight searching a cave for treasure, or a puppy running around a park, or a Roomba cleaning up a messy house.\n",
    "\n",
    "This initial part (Problem 0) is going to have a lot of text. But I swear it is worth reading through, because the next few problems will build off of this generic task environment framework.\n",
    "\n",
    "**Final note:** Many of these problems are intentionally open-ended. Part of the point is to get some practice designing objects, specifically to represent things that are much more overtly \"AI\" than search algorithms. But (in my view) much more of the point is to **exercise the creative side of programming**. If there was only one answer, it wouldn't be nearly as much fun. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's set up some generic classes to represent `Environment`, `Agent` and `Thing`. We have a bunch of methods defined for an `Environment`, all based on what we imagine our needs might be for having an agent running around in the environment, picking things up (vacuuming, eating, holding,...) and putting them back down (a vacuum being full and spitting dirt back out, a puppy putting a bone down so it can drink water,...).\n",
    "\n",
    "The first 3 methods are used to set up the environment, and populate it with things, or remove things from it:\n",
    "* constructor: we feed in the dimensions of a square grid environment, and subtract 1 from each to account for the fact that Python is 0-based, but we are sending in the number of tiles in each direction. The lower-left corner of the environment is assumed to be (0,0). The environment can also have `things` and `agents` in it, so we create a list for each of those.\n",
    "* `add_thing`: we want to be able to add things to the environment. Later, we will look at creating a class to represent `Thing`s.  We need as input to this a Thing and its location (Cartesian coordinates).\n",
    "* `remove_thing`: we might need to remove some things from the environment. \n",
    "\n",
    "The next 3 methods are useful for representing agents' **sensors**. Namely, we are concerned about whether or not the agent can sense things at or near the agent.\n",
    "* `things_near`: we might be interested to know what are all the things in the tiles *adjacent* to the agent's location (as well as at the agent's location), so we return this as a list.\n",
    "* `things_at`: perhaps we have an agent that can only sense what is going on in its location (otherwise, the same as `things_near`)\n",
    "* `percepts`: by default in this generic `Environment` class, the agents will be able to perceive anything *near* them. We can override this later depending on if we think our agent should be able to sense more or less.\n",
    "\n",
    "We have 3 methods to represent the agent moving through a 2D rectangular grid environment, as well as executing a couple other generic **actions**.\n",
    "* `hit_wall`: we know the boundaries of the environment, so if the agent tries to move outside of them, we need to let it know that it has bumped into a wall\n",
    "* `move`: the agent tries to execute a move\n",
    "* `execute_action`: here is the meat and cheese of the agent's actuators. In this generic class, we allow the agent to move in any of the four cardinal directions, as well as pick things up (`Grab`) and set things down (`Drop`).\n",
    "\n",
    "Finally, we need a few more methods to define how the actual simulation for the task environment is to proceed.\n",
    "* `is_done`: returns True if there are no more \"living\" agents to simulate\n",
    "* `step`: executes a single time step of the environment: the agent senses the environment, and then acts. This method by default is assuming a single agent, but we could override this to make it more general. You will notice that the `step` method is where we print output to the screen to stay apprised of what is going on in our virtual world.\n",
    "* `driver`: this is the driver method, which takes as an argument the number of time steps to run (default is 5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width-1    # relative to 0, so subtract 1\n",
    "        self.height = height-1\n",
    "        self.things = []\n",
    "        self.agents = []\n",
    "\n",
    "    #\n",
    "    # The following 2 methods allow us to add Things or remove Things from the environment\n",
    "    #\n",
    "    \n",
    "    def add_thing(self, thing, location):\n",
    "        '''Add a thing to the environment and set its location.\n",
    "        For convenience, if thing is an agent program we make a new agent for it.'''\n",
    "        # first, check if the desired location is in-bounds\n",
    "        out_of_bounds = (location[0] > self.width or location[0] < 0 or\n",
    "                         location[1] > self.height or location[1] < 0)\n",
    "        if out_of_bounds:\n",
    "            print('Warning: failed to add {} object at {}'.format(thing.__class__.__name__, location))\n",
    "            return\n",
    "\n",
    "        if not isinstance(thing, Thing):\n",
    "            thing = Agent(thing)\n",
    "        thing.location = location\n",
    "        self.things.append(thing)\n",
    "        if isinstance(thing, Agent):\n",
    "            self.agents.append(thing)\n",
    "\n",
    "    def remove_thing(self, thing):\n",
    "        if thing in self.things:\n",
    "            self.things.remove(thing)\n",
    "            return True\n",
    "        elif thing in self.agents:\n",
    "            self.agents.remove(thing)\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    #\n",
    "    # The next 3 methods set up the agent's perception of things around it (SENSORS)\n",
    "    #\n",
    "    \n",
    "    def things_near(self, location):\n",
    "        '''return all things around the given location'''\n",
    "        things = []\n",
    "        for thing in self.things:  \n",
    "            # look within a radius of 1 around the agent; on Cartesian grid, \n",
    "            # this will only return the Things at the adjacent squares\n",
    "            # NOTE: if you wanted to let the agent have great vision/better sensors, this\n",
    "            #       could be modified\n",
    "            if np.sqrt( (thing.location[0]-location[0])**2 + (thing.location[1]-location[1])**2) <= 1:\n",
    "                things.append(thing)\n",
    "        return things\n",
    "    \n",
    "    def things_at(self, location):\n",
    "        '''return all things at the given location'''\n",
    "        things = []\n",
    "        for thing in self.things:        \n",
    "            if thing.location==location:\n",
    "                things.append(thing)\n",
    "        return things\n",
    "    \n",
    "    def percepts(self, agent):\n",
    "        '''the agent can perceive things N/S/E/W of their location'''\n",
    "        return self.things_near(agent.location)\n",
    "\n",
    "    #\n",
    "    # The next 3 methods set up how the agent can interact with the environment (ACTUATORS)\n",
    "    #\n",
    "    \n",
    "    def hit_wall(self, location):\n",
    "        '''hit a wall/boundary if the agent tries to go out of bounds'''\n",
    "        return (location[0] > self.width or location[0] < 0 or location[1] > self.height or location[1] < 0)\n",
    "        \n",
    "    def move(self, agent, direction):\n",
    "        '''get the new agent location, but revert to old if it bumps into boundary'''\n",
    "        locx, locy = agent.location\n",
    "        if direction=='N':\n",
    "            newLocation = locx, locy+1    \n",
    "        elif direction=='S':\n",
    "            newLocation = locx, locy-1\n",
    "        elif direction=='E':\n",
    "            newLocation = locx+1, locy\n",
    "        elif direction=='W':\n",
    "            newLocation = locx-1, locy\n",
    "        bump = self.hit_wall(newLocation)\n",
    "        agent.location = newLocation if not bump else location\n",
    "        return (not bump)\n",
    "            \n",
    "    def execute_action(self, agent, action):\n",
    "        if action in ['N','S','E','W']:\n",
    "            bump = self.move(agent, action)\n",
    "        elif action == 'Grab':\n",
    "            things = [thing for thing in self.things_at(agent.location)]\n",
    "            if things:\n",
    "                agent.holding.append(things[0])\n",
    "                self.remove_thing(things[0])\n",
    "        elif action == 'Drop':\n",
    "            if agent.holding:\n",
    "                dropped = agent.holding.pop()\n",
    "                self.add_thing(thing=dropped, location=agent.location)\n",
    "\n",
    "    #\n",
    "    # These last 3 methods set up how the simulation for the task environment will be run\n",
    "    #\n",
    "    \n",
    "    def is_done(self):\n",
    "        '''end the simulation if there are no living agents (or end of time steps)'''\n",
    "        return not any(agent.is_alive() for agent in self.agents)\n",
    "\n",
    "    def step(self, quiet):\n",
    "        '''run one time step of the environment; assumes a single agent'''\n",
    "        if not self.is_done():\n",
    "            # assuming a single agent here!\n",
    "            agent = self.agents[0]\n",
    "            action = agent.function(self.percepts(agent))\n",
    "            if not quiet:\n",
    "                print('Agent {} executes action {} at location {}'.format(agent.name, action, agent.location))\n",
    "            self.execute_action(agent, action)\n",
    "\n",
    "    def driver(self, n_steps=5, quiet=False):\n",
    "        '''a driver method to run the environment for n_steps time steps\n",
    "        quiet=True will suppress output to screen to update (helpful for long simulations)'''\n",
    "        for step in range(n_steps):\n",
    "            self.step(quiet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, you've made it this far. You deserve a reward.  Here's a picture of a baby sloth wearing pajamas and taking a selfie.\n",
    "\n",
    "<img src=\"https://i.pinimg.com/736x/bc/4b/4c/bc4b4c4c01a6a82d8991524c9f41f6ce--pajamas-pjs.jpg\" style=\"width: 200px;\"/>\n",
    "\n",
    "\n",
    "Now then. We should define some generic classes for `Thing`s and `Agent`s.  We can consider an `Agent` to be a subclass of `Thing`, since it is just a special case of general objects that we are putting in our environment.\n",
    "\n",
    "Our generic `Thing` class is pretty sparse. Basically, we are going to throw down some objects and declare whether or not they are alive. It serves as a basis for representing other things later that we can add other useful attributes to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thing:\n",
    "    '''represent things in the environment'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def is_alive(self):\n",
    "        '''is this thing alive?'''\n",
    "        return hasattr(self, 'alive') and self.alive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can create an `Agent` as a subclass of `Thing`.  We should provide a **name** for our agents, and an **agent function**.  Recall that the agent function is what is \"doing the AI\". That is, the agent function takes as input the percepts, and provides as output the appropriate agent actions to take.\n",
    "\n",
    "Note that in case an agent function argument is not provided, we have a nice default course of action for a listless agent. There is also an attribute of the agent to store its `performance` measure, once we decide how to evaluate that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(Thing):\n",
    "    \n",
    "    def __init__(self, name, agent_function=None):\n",
    "        self.alive = True\n",
    "        self.name = name\n",
    "        self.holding = []\n",
    "        self.performance = 0\n",
    "        if agent_function is None:\n",
    "            print('Warning: Agent {} missing agent_function. Using a silly default.'.format(self.name))\n",
    "            \n",
    "            def agent_function(percepts):\n",
    "                '''Only move left. It is the finest direction, after all.\n",
    "                Note that this only is run if the user does not supply a valid agent_function'''\n",
    "                return 'W'\n",
    "\n",
    "        self.function = agent_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "[Back to top](#top)\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"http://www.irobotweb.com/-/media/Images/Product-Pages/Roomba-Learn/Mini-Compare/960-Product-Image.png?h=292&la=en&w=286\" alt=\"Drawing\" style=\"width: 120px;\"/>\n",
    "\n",
    "<a/ id='p1'></a>\n",
    "## Problem 1:  Let's talk Roombas.\n",
    "\n",
    "The generic `Environment`/`Thing`/`Agent` set-up above is a pretty nice framework for tackling a variety of problems, but we will need to override a few components of it to make this function well for the specific task environment of a Roomba cleaning up a dirty room.\n",
    "\n",
    "First, let's create a **simple reflex agent**, `ReflexRoombaAgent`, method.  This function will take in an argument **name**, representing the agent's name.  Then, an `agent_function` is defined.  This is the most problem-specific part.  The `agent_function` below is specific to our simple two-tile environment that we will play around with initially.  Later, we will modify and extend this to larger rooms, and to other problems.\n",
    "\n",
    "After defining the `agent_function`, the `ReflexRoombaAgent` constructs an `Agent` object using the generic template above, but with Roomba-specific programming (i.e., `agent_function`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReflexRoombaAgent(name):\n",
    "    '''reflex Roomba agent. Takes percept as input, which is a tuple of (location, status)\n",
    "    and returns the appropriate action. This will override the default in the Agent class of \n",
    "    only moving West'''\n",
    "    def agent_function(percepts):\n",
    "        location, status = percepts\n",
    "        if status == 'Dirty':\n",
    "            return 'Vacuum'\n",
    "        elif location == (0,0):\n",
    "            return 'E'\n",
    "        elif location == (1,0):\n",
    "            return 'W'\n",
    "        \n",
    "    return Agent(name, agent_function)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Roomba is going to need some `Thing`s to clean up - namely, dirt! So let's create a subclass of `Thing` to represent dirt. If you haven't seen or used the `pass` statement in Python, it is just a placeholder when there needs to be *some*thing in that line, since Python syntax relies on whitespace. (Otherwise, we wouldn't know when to end the definition for the Dirt class.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dirt(Thing):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a Roomba and Dirt, specific to our vacuum task environment, let's make the `Environment` a bit more problem-specific.  The agent interacts with the environment through percepts and actuators, so we will need to override those defaults from the main Environment class. \n",
    "\n",
    "For `percepts`, we will assume that the agent can sense (1) its location and (2) whether that location is clean or dirty.  `percepts` takes as the argument the **agent**, and returns a tuple of (**location**, **status**).  Note that the actual \"sensing\" is done by the `Environment` method `things_at(location)`. That line checks whether or not any of the `things_at` the agent's location are of class Dirt. Note that it is possible to have multiple instances of Dirt in  given location, which could reflect the fact that in real life, sometimes our house is just really gross.\n",
    "\n",
    "For actuators, the generic `execute_action` method is almost good enough. We can override the `Grab` action with something more meaningful to our application.  Let's rename that as `Vacuum`, and call the things we want to grab `messes`.\n",
    "\n",
    "We only want the Roomba to pick up things that are Dirt (ideally), so we add the condition `if isinstance(thing, Dirt)`.  Notice that the Roomba will only pick up the *first* unit of dirt that it senses. This reflects the reality that if a tile is *really* dirty, it should take the Roomba longer to clean it up than a just mildly dirty tile.\n",
    "\n",
    "Notice that we also store in Roomba's `holding` attribute all of the different units of dirt that it has picked up. Later, we will generalize this problem so that Roomba can only store a finite amount of dirt, which is of course how real vacuums work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VacuumEnvironment(Environment):\n",
    "            \n",
    "    def percepts(self, agent):\n",
    "        ''' the percept is a tuple of (location, status) '''\n",
    "        status = 'Dirty' if any([isinstance(item, Dirt) \n",
    "                                 for item in room.things_at(location=agent.location)]) else 'Clean'\n",
    "        return (agent.location, status)\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        ''' override the default execute_action in Environment class, so that\n",
    "        for the Roomba we remove '''\n",
    "        if action in ['N','S','E','W']:\n",
    "            bump = self.move(agent, action)\n",
    "        elif action == 'Vacuum':\n",
    "            messes = [thing for thing in room.things_at(roomba.location) if isinstance(thing, Dirt)]\n",
    "            if messes:\n",
    "                agent.holding.append(messes[0])\n",
    "                self.remove_thing(messes[0])\n",
    "        elif action == 'Drop':\n",
    "            if agent.holding:\n",
    "                dropped = agent.holding.pop()\n",
    "                self.add_thing(thing=dropped, location=agent.location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a/ id='p1a'></a>\n",
    "### (1a)\n",
    "\n",
    "#### Enough chit chat. Play time!\n",
    "\n",
    "Create a **room** that is a `VacuumEnvironment` with width=2 and height=1 (i.e., the standard two-tile room from the introductory set of slides where we introduced the concept of agents). Notice that the Cartesian coordinates of the tiles are (0,0) and (1,0), for a width of 2 and height of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "room = VacuumEnvironment(width=2, height=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have a room, and that room can get dirty, we should probably instantiate a `ReflexRoombaAgent`.  Since our `ReflexRoombaAgent` is of class `Agent`, which is a subclass of `Thing`, we will need to use the `add_thing` method to add our Roomba to the **room**.  Here, you can see that we are adding the Roomba to the tile at (0,0).\n",
    "\n",
    "**Most importantly:** Give your Roomba a sweet name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "roomba = ReflexRoombaAgent('Speedy')\n",
    "room.add_thing(roomba, location=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to set up the environment, let's sprinkle some dirt around.  In fact, let's set it up so that both tiles are `Dirty`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "room.add_thing(Dirt(), location=(0,0))\n",
    "room.add_thing(Dirt(), location=(1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At long last, we are ready to actually run our simulation.  Let's run for 6 time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Speedy executes action Vacuum at location (0, 0)\n",
      "Agent Speedy executes action E at location (0, 0)\n",
      "Agent Speedy executes action Vacuum at location (1, 0)\n",
      "Agent Speedy executes action W at location (1, 0)\n",
      "Agent Speedy executes action E at location (0, 0)\n",
      "Agent Speedy executes action W at location (1, 0)\n"
     ]
    }
   ],
   "source": [
    "room.driver(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that looks like it went smoothly.  We should check that everything is working though.  After 6 time steps, the Roomba should have been able to vacuum up the patches of dirt in both tiles.  Then, what does the agent do? Check out the `agent_function` definition to make sure that, after the agent vacuums up all the dirt, it does what you expect.\n",
    "\n",
    "We can also check to make sure the list of things in the room, and the list of what all the Roomba agent is holding, both match our expectations.  What should be left in the room?  What should Roomba be holding?  Design a couple `print` statements to check that our task environment looks the way we expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Things left in the room: ['Agent']\n",
      "Things agent is holding: ['Dirt', 'Dirt']\n"
     ]
    }
   ],
   "source": [
    "print('Things left in the room: {}'.format([thing.__class__.__name__ for thing in room.things]))\n",
    "print('Things agent is holding: {}'.format([thing.__class__.__name__ for thing in roomba.holding]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Now that we have a basic Roomba agent in a very simple room, let's start to add in layers of complexity/reality. Each part of the rest of this problem adds another feature or set of features to make our Roomba Agents a bit more like actual Roombas.  By the end of this problem, our \"toy\" Roombas will be pretty similar to actual Roombas.\n",
    "\n",
    "For the next few parts, my approach would be to only modify the Roomba-specific programming from **Problem 1** and beyond; try to leave the stuff in **Problem 0** alone, if you can. The point of the `ReflexRoombaAgent` and `VacuumEnvironment` classes is to take the generic `Agent` and `Environment` classes and apply vacuum-specific methods, as opposed to hard-coding the entire gory mess from (e.g.) the `Environment` class in **Problem 0**. So, instead of jumping back and forth to modify the codes from **1a**, the easiest thing to do to implement these additional code features is probably to begin by copy-pasting, but then giving the new subclasses here new names.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a/ id='p1b'></a>\n",
    "### (1b)\n",
    "\n",
    "Also implement the following features. It is probably easiest to do these **one at a time**, to make sure you know which breaks your code if things go off the rails.\n",
    "1. Include a performance measure for the agent to keep track of.  You should decide for yourselves how you want to measure your Roomba's performance. Here are some general guidelines:\n",
    "  * Reward cleanliness\n",
    "  * Penalize excessive moving around\n",
    "1. Implement a model-based agent\n",
    "  * Keep track of which tiles are clean/dirty\n",
    "  * Perhaps use an attribute of the agent called **model** that updates the agent's internal map of where the clean/dirty tiles all are. The entire room is initially unknown.\n",
    "  * For example, if the Roomba agent has just come from cleaning the tile at (0,0), and has now just cleaned the tile at (1,0), then the Roomba ought to know that going straight back to (0,0) is not the best option.\n",
    "  * You may want to add a **NoOp** (\"no operation\" or \"do nothing\") action choice, since moving around unnecessarily will worsen the agent's performance measure.\n",
    "1. Stochastically generate new dirt every so often\n",
    "  * Based on how long it has been since the agent last cleaned a particular tile, it may be necessary to circle back around and check the tiles again for dirt (since it may have appeared stochastically). Thus, the agent will need to track in its model *how long* it has been since it has cleaned each tile.\n",
    "  * It may be useful to print a message to the screen denoting the location of new dirt, if dirt appears somewhere.\n",
    "\n",
    "The following code snippet could implement stochastic dirt appearance with probability `p_dirt` for each tile for each time step.  You are encouraged to modify `p_dirt` as you see fit.  The default here is a 1/10 probability of dirt appearing on any given tile at any given time step, possibly from a puppy with muddy paws or a roommate just returning from a hike.  Note that *all* tiles will need to be updated in this way, and that `p_dirt` is probably most appropriate to specify as an attribute of the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dirt = 0.1\n",
    "updateStatus = np.random.choice(['Clean','Dirty'], p=[1-p_dirt, p_dirt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "\n",
    "def ModelBasedRoombaAgent(name, wait_limit=5):\n",
    "    \n",
    "    model = {(0,0) : [None,0], (1,0) : [None,0]}\n",
    "\n",
    "    def agent_function(percepts):\n",
    "        location, status = percepts\n",
    "        \n",
    "        #update the agent's internal model\n",
    "        model[location][0] = status\n",
    "        \n",
    "        # NoOp strategy:\n",
    "        if all(model[k][0]=='Clean' and model[k][1] <= wait_limit for k in model.keys()):\n",
    "            for k in model.keys():\n",
    "                model[k][1] += 1 \n",
    "            return 'NoOp'\n",
    "        elif status == 'Dirty':\n",
    "            for k in model.keys():\n",
    "                if location==k:\n",
    "                    model[k][1] = 0\n",
    "                else:\n",
    "                    model[k][1] += 1\n",
    "            return 'Vacuum'\n",
    "        elif location == (0,0):\n",
    "            for k in model.keys():\n",
    "                if location!=k:\n",
    "                    model[k][1] += 1\n",
    "            return 'E'\n",
    "        elif location == (1,0):\n",
    "            for k in model.keys():\n",
    "                if location!=k:\n",
    "                    model[k][1] += 1\n",
    "            return 'W'\n",
    "        \n",
    "    return Agent(name, agent_function)  \n",
    "\n",
    "class PerformanceVacuumEnvironment(Environment):\n",
    "\n",
    "    def __init__(self, width, height):\n",
    "        self.width = width-1    # relative to 0, so subtract 1\n",
    "        self.height = height-1\n",
    "        self.things = []\n",
    "        self.agents = []\n",
    "        self.p_dirt = 0.1\n",
    "\n",
    "    def percepts(self, agent):\n",
    "        ''' the percept is a tuple of (location, status) '''\n",
    "        status = 'Dirty' if any([isinstance(item, Dirt) \n",
    "                                 for item in room.things_at(location=agent.location)]) else 'Clean'\n",
    "        return (agent.location, status)\n",
    "\n",
    "    def execute_action(self, agent, action):\n",
    "        ''' override the default execute_action in Environment class, so that\n",
    "        for the Roomba we remove '''\n",
    "        if action in ['N','S','E','W']:\n",
    "            bump = self.move(agent, action)\n",
    "            agent.performance -= 1\n",
    "        elif action == 'Vacuum':\n",
    "            messes = [thing for thing in room.things_at(roomba.location) if isinstance(thing, Dirt)]\n",
    "            if messes:\n",
    "                agent.holding.append(messes[0])\n",
    "                self.remove_thing(messes[0])\n",
    "                agent.performance += 10\n",
    "        elif action == 'Drop':\n",
    "            if agent.holding:\n",
    "                dropped = agent.holding.pop()\n",
    "                self.add_thing(thing=dropped, location=agent.location)\n",
    "                \n",
    "    def step(self, quiet):\n",
    "        '''run one time step of the environment; assumes a single agent'''\n",
    "        if not self.is_done():\n",
    "            # assuming a single agent here!\n",
    "            agent = self.agents[0]\n",
    "            action = agent.function(self.percepts(agent))\n",
    "            if not quiet:\n",
    "                print('Agent {} executes action {} at location {}'.format(agent.name, action, agent.location))\n",
    "            self.execute_action(agent, action)\n",
    "            # generate new dirt, maybe\n",
    "            for x in range(self.width+1):\n",
    "                for y in range(self.height+1):\n",
    "                    updateStatus = np.random.choice(['Clean','Dirty'], p=[1-self.p_dirt, self.p_dirt])\n",
    "                    if updateStatus=='Dirty':\n",
    "                        self.add_thing(Dirt(), (x,y))\n",
    "                        if not quiet:\n",
    "                            print('Dirt appeared at ({},{})!'.format(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be a relationship between the agent's performance, the frequency with which new dirt stochastically appears (`p_dirt`), and your `NoOp` action strategy (which avoids excessive moving around).  This might be easiest to think about in terms of the limiting cases:\n",
    "* What should be the agent's `NoOp` strategy if `p_dirt` = 1?\n",
    "* What should be the agent's `NoOp` strategy if `p_dirt` = 0?\n",
    "\n",
    "Note that we don't have any control over `p_dirt`; it is a property of how filthy our living conditions are. All we can do is specify the Roomba's `NoOp` strategy (waiting time before circling back to check for new dirt) as best we can.\n",
    "\n",
    "So, try a few very long simulations (you might want to suppress the printed output for these) with different combinations of `NoOp` strategy and `p_dirt` values.  For a couple different values of `p_dirt`, what do you find to be the optimal `NoOp` strategies? That is, what waiting time (once the agent knows it has cleaned everything) will maximize the agent's performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solution:\n",
    "\n",
    "perf = []\n",
    "wait_limits = [1,2,5,10,20,50,100,200]\n",
    "\n",
    "for w in wait_limits:\n",
    "    room = PerformanceVacuumEnvironment(width=2, height=1)\n",
    "    roomba = ModelBasedRoombaAgent('Rufus', w)\n",
    "    room.add_thing(roomba, (0,0))\n",
    "    room.add_thing(Dirt(), (0,0))\n",
    "    room.add_thing(Dirt(), (1,0))\n",
    "    room.driver(1000, quiet=True)\n",
    "    perf.append(np.mean(roomba.performance))\n",
    "\n",
    "plt.plot(wait_limits, perf)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**\n",
    "\n",
    "Note that your results might vary, depending on your choices for `p_dirt` and the wait limits.  You can also obtain better results by doing this many times and taking the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a/ id='p1c'></a>\n",
    "\n",
    "### (1c)\n",
    "\n",
    "Let's continue to build this up! We can make things a bit more interesting by increasing the size of the room. Add the following features to your codes from **(1b)**:\n",
    "* Try a 2x2 room first.\n",
    "* In the example codes, Roomba knew the geography of the environment (i.e., that it is a 2x1 room), so it knew the options for moving around.\n",
    "  * As a first attempt for your 2x2 room, make this assumption.  Thus, the Roomba's choices of action to execute will depend on its sensed location.\n",
    "    * Note that if Roomba is at (0,0), and senses that this tile is clean, but has no information about (1,0) or (0,1), then it should choose at random where to go next. A modification of the `np.random.choice` function call above can take care of this.\n",
    "  * Once that seems to work, try to incorporate the fact that the Roomba typically does not know a priori what the shape of the room is. \n",
    "    * The easiest first step to build this into your model is to have Roomba sense its environment: if dirty, then clean the tile; if clean, then move randomly. (This is how I clean my apartment.)\n",
    "    * Then you can try building a **map** of the room as part of the Roomba's model. So as the random-movement Roomba flails around, it will sometimes bump into a wall.  But if it senses a bump, then Roomba can *learn* where the walls are, and what the available actions are depending on where in the room it is.\n",
    "    * Holy heck, we just built a *learning* model-based agent!\n",
    "* Once your Roomba is successfully tidying up a 2x1 or 2x2 room, go bigger!\n",
    "* It might be useful to note that the only thing that really needs to change is your `agent_function`, which maps percepts to actions. The `VacuumEnvironment` class is already able to handle arbitrary-sized rooms. So selecting an action will need to be modified, as well as how the agent builds its internal model of the task environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<a/ id='p1d'></a>\n",
    "\n",
    "### (1d)\n",
    "\n",
    "Let's add two more related details that will really make this Roomba more realistic.\n",
    "* Roombas have a certain amount of **charge**, which depletes as time goes on. You could incorporate this into the model in a few different ways. Use your ingenuity and creativity to decide how to implement this! If you get stuck, ask other groups or ask me.\n",
    "  * This means that your Roomba is going to need a particular location as a charging spot, and should return to it every so often.\n",
    "  * It is probably reasonable to assume that your Roomba knows how long (how many time steps) it takes to deplete its battery. As part of Roomba's model, it should keep track of how long it will take to return to the charging port and how much battery life remains.\n",
    "  * If the battery falls below a critical point, return to base!\n",
    "  * What should happen if the battery is fully depleted?\n",
    "* Roombas also can only hold a **finite amount of dirt**.\n",
    "  * If the dirt gets \"full\" (you will need to implement some dirt limit as part of the agent), then the Roomba can't vacuum anymore and needs to return to the charging port to dump its dirt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
